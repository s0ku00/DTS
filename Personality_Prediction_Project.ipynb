{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s0ku00/DTS/blob/main/Personality_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce1ebdXVFlk2"
      },
      "source": [
        "# Personality Prediction Project\n",
        "## Project Framework\n",
        "The primary prediction objective is to build a predictive model that classifies individuals as Introvert or Extrovert based on features describing social behavior and lifestyle patterns.\n",
        "\n",
        "* Hypothesis 1: Individuals who report spending more time alone and feel drained after socializing are more likely to be introverts.\n",
        "*\tHypothesis 2: Extroversion is correlated with larger friends_circle_size and higher post_frequency.\n",
        "\n",
        "## Dataset Description\n",
        "Extrovert vs Introvert Behavior Data : https://www.kaggle.com/datasets/rakeshkapilavai/extrovert-vs-introvert-behavior-data/data?select=personality_dataset.csv\n",
        "\n",
        "### Features\n",
        "* Time_spent_Alone -\tHours spent alone per day\n",
        "* Stage_fear -\t1 = Yes, 0 = No\n",
        "* Social_event_attendance\t- Number of social events attended monthly\n",
        "* Going_outside\t- Frequency of going outside\n",
        "* Drained_after_socializing -\t1 = Yes, 0 = No\n",
        "* Friends_circle_size -\tNumber of friends\n",
        "* Post_frequency -\tFrequency of posting on social media\n",
        "* Personality\t- Target variable (Introvert/Extrovert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlW-qaHPGEiO"
      },
      "source": [
        "## Loading and inspecting the dataset\n",
        "\n",
        "* The dataset has 2900 rows and 8 columns.\n",
        "* 5 numeric columns and 3 categorical columns, including the target column(Personality)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfKEEMGUb6Hu",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install ydata_profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w4LxwdjrNvB"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
        "from sklearn import tree\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UroUJ9dSNSsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Jsab3ckNf3e_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/personality_dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYGZZA5o7jcK"
      },
      "outputs": [],
      "source": [
        "print(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcEsJPqMG1yW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.describe(include= 'all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV3M-d-ZhmRs",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPU-xG1kNy11",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R3vzDgWwx5j"
      },
      "source": [
        "## Handling Duplicates\n",
        "The dataset contains 388 duplicated rows, I decided to drop the duplicated rows to avoid model bias. Most of the duplicated rows were introverts and this slightly changed the class distribution from 51% Extrovert / 49% Introvert to 56% Extrovert / 44% Introvert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQkuQFBdiQoY"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "svq7LwHHuc3P"
      },
      "outputs": [],
      "source": [
        "duplicates_df = df.copy()\n",
        "duplicates = duplicates_df[duplicates_df.duplicated(keep=False)]\n",
        "display(duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7XGEEib43C7"
      },
      "outputs": [],
      "source": [
        "# Before removing duplicates\n",
        "\n",
        "print(\"Class balance BEFORE removing duplicates:\\n\")\n",
        "print(df['Personality'].value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hntwsjLzUp-"
      },
      "outputs": [],
      "source": [
        "# After removing duplicates\n",
        "\n",
        "df_clean = df.drop_duplicates()\n",
        "print(\"Class balance AFTER removing duplicates:\\n\")\n",
        "print((df_clean['Personality'].value_counts(normalize=True) * 100).round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s62r6CRmDjqF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df_clean.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoMfuXODdCF"
      },
      "source": [
        "## Handling missing values\n",
        "* Missing values unique row count is 414 which means 16.5% of the dataset have missing values. This value is too high to drop.\n",
        "\n",
        "* Numerical missing values were filled using KNN imputer.\n",
        "\n",
        "* Categorical missing values were filled using mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfN-CmPoCoy1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df_clean.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyxWHdzZDMiE"
      },
      "outputs": [],
      "source": [
        "df_clean.isnull().any(axis=1).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7or2d6TE_X1V"
      },
      "outputs": [],
      "source": [
        "# Defining categorical and numeric columns\n",
        "cat_columns = ['Stage_fear', 'Drained_after_socializing']\n",
        "\n",
        "num_columns = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
        "\n",
        "target = 'Personality'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHQhBl4zxFCI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "display(df[\"Stage_fear\"].value_counts(dropna=False))\n",
        "display(df[\"Drained_after_socializing\"].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i5ZHWWVCN9z",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "stage_fear_counts = df_clean.groupby([\"Stage_fear\", \"Personality\"]).size().unstack()\n",
        "\n",
        "stage_fear_counts.plot(\n",
        "    kind=\"bar\",\n",
        "    stacked=True,\n",
        "    figsize=(8,6)\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Stage Fear\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Stage Fear Distribution by Personality Type\")\n",
        "plt.legend(title=\"Personality\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xjptbOjX8Pn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "Drained_after_socializing_count = df_clean.groupby([\"Drained_after_socializing\", \"Personality\"]).size().unstack()\n",
        "\n",
        "Drained_after_socializing_count.plot(\n",
        "    kind=\"bar\",\n",
        "    stacked=True,\n",
        "    figsize=(8,6)\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Stage Fear\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Drained After Socializing Count Distribution by Personality Type\")\n",
        "plt.legend(title=\"Personality\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_columns:\n",
        "    df_clean.loc[:, col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
        "    print(f\"Missing values in {col} column: {df_clean[col].isnull().sum()}\")"
      ],
      "metadata": {
        "id": "VcnBiotC5WWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df_clean[num_columns] = imputer.fit_transform(df_clean[num_columns])\n",
        "print(df_clean[num_columns].isnull().sum())"
      ],
      "metadata": {
        "id": "52y18XDy9F58",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.shape"
      ],
      "metadata": {
        "id": "BLVAnuQM-ZI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WlCx94KaB8M"
      },
      "source": [
        "## Checking for outliers\n",
        "There are no outliers in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSLQm1v2Z5KO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "outlier_summary = {}\n",
        "\n",
        "for col in num_columns:\n",
        "    Q1 = df_clean[col].quantile(0.25)\n",
        "    Q3 = df_clean[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df_clean[(df_clean[col] < lower) | (df_clean[col] > upper)]\n",
        "    outlier_summary[col] = len(outliers)\n",
        "\n",
        "outlier_summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=df_clean[num_columns])\n",
        "plt.title('Box plots for numeric columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q4r8AIcfAcrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "### Key findings\n",
        "* Visible separation between extroverts and introverts across multiple features.\n",
        "\n",
        "* Higher Time_spent_Alone is frequently associated with Introverts.\n",
        "\n",
        "* People with large friend circles tend to classify as Extroverts.\n",
        "\n",
        "* Time spent alone has a negative correlation with all other numerical columns.\n",
        "\n",
        "* AttendingÂ social events and the size of friends' circles are positively correlated with extroversion.\n",
        "\n",
        "* PCA plot reflected the introversion and extroversion axis, clearly separating the groups.\n",
        "\n",
        "* Some introverts and extroverts showed behaviors that are counterintuitive, might suggest a third class (Ambiverts) *italicized text*"
      ],
      "metadata": {
        "id": "0S6-J7Q-vh0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XnWJ9Gtb24N",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Create ydata_profiling Report\n",
        "profile = ProfileReport(df, title='Telecom Churn Profiling Report')\n",
        "\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "P13K7WDaJTFm"
      },
      "outputs": [],
      "source": [
        "# Plotting the distribution of the numerical columns\n",
        "for col in num_columns:\n",
        "    plt.figure(figsize=(6,3))\n",
        "    sns.histplot(df_clean[col], kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJTUvJXKO9JW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_clean, hue=\"Personality\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2W5aRA4CKRt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df[num_columns].corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Transformation\n",
        "X_pca = df_clean[num_columns]\n",
        "\n",
        "X_scaled_pca = StandardScaler().fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "components = pca.fit_transform(X_scaled_pca)\n"
      ],
      "metadata": {
        "id": "kW-KWl2gGA3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_df = pd.DataFrame({\n",
        "    \"PCA1\": components[:, 0],\n",
        "    \"PCA2\": components[:, 1],\n",
        "    \"Personality\": df_clean[\"Personality\"]\n",
        "})\n",
        "\n",
        "sns.scatterplot(data=pca_df, x=\"PCA1\", y=\"PCA2\", hue=\"Personality\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ld_jwmEAGN5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "\n",
        "* Encoding the categorical features and target variable.\n",
        "* Split the data into 80% training data and 20% test data.\n",
        "* Used StandardScaler to scale the features."
      ],
      "metadata": {
        "id": "CRiCEsxxqgTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the categorical variables\n",
        "le = LabelEncoder()\n",
        "df_clean[\"Stage_fear\"] = le.fit_transform(df_clean[\"Stage_fear\"])\n",
        "df_clean[\"Drained_after_socializing\"] = le.fit_transform(df_clean[\"Drained_after_socializing\"])\n",
        "df_clean[\"Personality\"] = le.fit_transform(df_clean[\"Personality\"])\n",
        "\n",
        "df_clean"
      ],
      "metadata": {
        "id": "B7gSVQmEmhmW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the data into test and train\n",
        "\n",
        "X = df_clean.drop(\"Personality\", axis=1)\n",
        "y = df_clean[\"Personality\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "NN2RY76BKzLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "nUl0HWmzODPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building\n",
        "\n",
        "* Support Vector Machine (SVM) is the Best model, with an accuracy of 91%.\n",
        "\n",
        "* Logistic Regression and SVM highlights emotional & social exhaustion as the strongest predicting features.\n",
        "\n",
        "* Random forest focused more on activities (event attendance, time alone) rather than emotional factors.\n",
        "\n",
        "* The accuracy for Random Forest is slightly lower than LR/SVM.\n",
        "\n",
        "## Model\taccuracy\n",
        "* SVM\t- 0.9145\n",
        "* Logistic Regression\t- 0.9125\n",
        "* Random Forest\t- 0.8986\n"
      ],
      "metadata": {
        "id": "w2a2WV4-qaGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "jtt5POZ8NQQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression WITHOUT SMOTE\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = log_reg.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "Y6hFSL9MygcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(log_reg, X_test_scaled, y_test)\n",
        "plt.title(\"Logistic Regression - Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yDpL2HrSui9o",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': log_reg.coef_[0]\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(coef_df)"
      ],
      "metadata": {
        "id": "L89k5xWbOiq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "QDuZ8mIIOOiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "muui3pa8Np3A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(svm, X_test_scaled, y_test)\n",
        "plt.title(\"SVM - Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EZNUL__YurzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(svm, X_test_scaled, y_test, n_repeats=20)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': result.importances_mean\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "cB4vlhaMSYCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "hH1DAFGuNJQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "jZqI4hYqNIPL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(rf_model, X_test_scaled, y_test)\n",
        "plt.title(\"Random Forest - Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e9K_XLaQuxyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Built-in feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importance_df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZJh9Gw4L0BGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future improvement\n",
        "* Evaluate on original (unscaled) test labels.\n",
        "\n",
        "* Predict a third class (Ambiverts)\n",
        "\n",
        "* Hyperparameter Tuning\n",
        "\n",
        "* Building a Streamlit app for personality prediction"
      ],
      "metadata": {
        "id": "8f0kAGJXsDid"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ce1ebdXVFlk2",
        "XlW-qaHPGEiO",
        "_R3vzDgWwx5j",
        "xwoMfuXODdCF",
        "0WlCx94KaB8M",
        "0S6-J7Q-vh0y",
        "CRiCEsxxqgTq",
        "jtt5POZ8NQQ9",
        "QDuZ8mIIOOiI",
        "hH1DAFGuNJQh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}